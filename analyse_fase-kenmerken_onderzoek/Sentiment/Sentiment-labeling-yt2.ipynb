{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee337f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aantal video records: 527\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "df1 = pd.read_json(\n",
    "    'radical/aqcuisition_fase-scrapers/Youtube/output/yt_results_uniq_with_comments.jsonl',\n",
    "    lines=True\n",
    ")\n",
    "\n",
    "print(\"Aantal video records:\", len(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6db06f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd4138e8eb7848478680d233e9688260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = \"tabularisai/multilingual-sentiment-analysis\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "model.eval()\n",
    "\n",
    "sentiment_map = {\n",
    "    0: \"Very Negative\",\n",
    "    1: \"Negative\",\n",
    "    2: \"Neutral\",\n",
    "    3: \"Positive\",\n",
    "    4: \"Very Positive\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23e71e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totaal aantal comments: 85920\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "for _, video in df1.iterrows():\n",
    "    video_id = video.get(\"video_id\")\n",
    "\n",
    "    for c in video.get(\"comment_list\", []):\n",
    "        rows.append({\n",
    "            \"video_id\": video_id,\n",
    "            \"published_at\": c.get(\"published_at\"),\n",
    "            \"author\": c.get(\"author\"),\n",
    "            \"text\": c.get(\"text\", \"\"),\n",
    "            \"is_reply\": False,\n",
    "        })\n",
    "\n",
    "        for r in c.get(\"replies\", []):\n",
    "            rows.append({\n",
    "                \"video_id\": video_id,\n",
    "                \"published_at\": r.get(\"published_at\"),\n",
    "                \"author\": r.get(\"author\"),\n",
    "                \"text\": r.get(\"text\", \"\"),\n",
    "                \"is_reply\": True,\n",
    "            })\n",
    "\n",
    "comments_df = pd.DataFrame(rows)\n",
    "comments_df[\"text\"] = comments_df[\"text\"].astype(str)\n",
    "\n",
    "print(\"Totaal aantal comments:\", len(comments_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "514249b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batched(texts, batch_size=16, max_length=256):\n",
    "    labels, confs = [], []\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "\n",
    "        inputs = tokenizer(\n",
    "            batch,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=max_length\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "        for p in probs:\n",
    "            idx = torch.argmax(p).item()\n",
    "            labels.append(sentiment_map[idx])\n",
    "            confs.append(float(p[idx]))\n",
    "\n",
    "        del inputs, outputs, probs\n",
    "\n",
    "    return labels, confs\n",
    "\n",
    "\n",
    "labels, confs = predict_batched(\n",
    "    comments_df[\"text\"].tolist(),\n",
    "    batch_size=16,   # verlaag naar 8 als RAM problemen\n",
    "    max_length=256   # verlaag naar 128 bij lange comments\n",
    ")\n",
    "\n",
    "comments_df[\"sentiment\"] = labels\n",
    "comments_df[\"confidence\"] = confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "518004fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 85920 entries, 0 to 85919\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   video_id      85920 non-null  str    \n",
      " 1   published_at  85920 non-null  str    \n",
      " 2   author        85920 non-null  str    \n",
      " 3   text          85920 non-null  str    \n",
      " 4   is_reply      85920 non-null  bool   \n",
      " 5   sentiment     85920 non-null  str    \n",
      " 6   confidence    85920 non-null  float64\n",
      "dtypes: bool(1), float64(1), str(5)\n",
      "memory usage: 4.0 MB\n"
     ]
    }
   ],
   "source": [
    "comments_df.head()\n",
    "comments_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "531d2b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df.to_json('radical/analyse_fase-kenmerken_onderzoek/Data/yt_comments_sentiment-labeld.json', orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
